{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torch.utils.data import Dataset\n",
    "from unet_model import UNet\n",
    "from kornia.filters import spatial_gradient\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"dataset/\"\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 8\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path=\"dataset/x_train.npy\", y_path=\"dataset/y_train.npy\", transform_flag=False):\n",
    "        self.X = np.load(X_path).transpose(0, 3, 1, 2)\n",
    "        self.y = np.load(y_path)\n",
    "        self.transform_flag = transform_flag\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def transform(self, image, mask):\n",
    "        # Random crop\n",
    "        image = torch.tensor(image)\n",
    "        mask = torch.tensor(mask)\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(256,256))\n",
    "        image = transforms.functional_tensor.crop(image, i, j, h, w)\n",
    "        mask = transforms.functional_tensor.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = transforms.functional_tensor.hflip(image)\n",
    "            mask = transforms.functional_tensor.hflip(mask)\n",
    "        \n",
    "        # Random brightness\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_brightness(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Contrast\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_contrast(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Gamma\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_gamma(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        # Random Hue\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_hue(image, np.random.rand() - 0.5)\n",
    "            \n",
    "        # Random Saturation\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_saturation(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform_flag:\n",
    "            return self.transform(self.X[idx], np.expand_dims(self.y[idx], 0))\n",
    "        else:\n",
    "            return self.X[idx], np.expand_dims(self.y[idx], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"dataset/x_train.npy\", \"dataset/y_train.npy\", transform_flag=True)\n",
    "val_dataset = MyDataset(\"dataset/x_val.npy\", \"dataset/y_val.npy\", transform_flag=False)\n",
    "test_dataset = MyDataset(\"dataset/x_test.npy\", \"dataset/y_test.npy\", transform_flag=False)\n",
    "\n",
    "# Create the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = 'cpu'\n",
    "\n",
    "# # Plot some training images\n",
    "# real_batch = next(iter(train_loader))\n",
    "# plt.figure(figsize=(8,8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for batch_idx, (data, target) in enumerate((train_loader)):\n",
    "    axes[0].imshow(np.transpose(data[0], (1,2,0)))\n",
    "    axes[1].imshow(np.transpose(target[0], (1,2,0)))\n",
    "    #print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelG = UNet(3, 1, bilinear=False)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"models/Unet_l1/model_100.pth\"))\n",
    "modelG = modelG.to(device)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "\n",
    "print(modelG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(13*13, 36),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(36, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nc, ndf , 4, 2, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf*2 , 4, 2, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf*2)\n",
    "        self.conv3 = nn.Conv2d(ndf *2, ndf * 4 , 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf*4)\n",
    "        self.conv4 = nn.Conv2d(ndf *4, ndf * 8 , 4, 2, 1, bias=False)\n",
    "        self.conv5 = nn.Conv2d(ndf *8, 1, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf*8)\n",
    "        self.fc1 = nn.Linear(64, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.bn1(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn2(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.bn3(self.conv4(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv5(x), 0.2)\n",
    "        #print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD = Discriminator().to(device)\n",
    "print(modelD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = torch.optim.Adam(modelG.parameters(), lr=0.01, weight_decay = 1e-3)\n",
    "optimizerD = torch.optim.Adam(modelD.parameters(), lr=0.01, weight_decay = 1e-3)\n",
    "\n",
    "criterionD = nn.BCELoss()\n",
    "\n",
    "(data, target) = next(iter(val_loader))\n",
    "fixed_data = data.to(device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleInvLoss(pred, groundtruth, lamda = 1, grad=True):\n",
    "    #as implemented in https://arxiv.org/pdf/1406.2283.pdf\n",
    "    log_pred = torch.log(pred)\n",
    "    log_gt = torch.log(groundtruth)\n",
    "    d = log_pred - log_gt\n",
    "    n = torch.numel(pred)\n",
    "    first_term = torch.sum(d**2)/n\n",
    "    second_term = torch.sum(d)**2 / n**2\n",
    "    if grad:\n",
    "        grad = spatial_gradient(d)\n",
    "        grad = torch.mean(grad**2)\n",
    "        return first_term - lamda * second_term + grad\n",
    "    else:\n",
    "        return first_term - lamda * second_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "num_epochs = 100\n",
    "mix_par = 0.5\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, (data, target) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        modelD.zero_grad()\n",
    "        # Format batch\n",
    "        target = target.to(device)\n",
    "        #print(target.shape)\n",
    "        b_size = target.size(0)\n",
    "        \n",
    "        #label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = modelD(target)\n",
    "        label = torch.ones_like(output)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterionD(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        data= data.to(device)\n",
    "        fake = modelG(data.float())\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = modelD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        label = torch.zeros_like(output)\n",
    "        errD_fake = criterionD(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        modelG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = modelD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterionD(output, label)\n",
    "        # Calculate gradients for G\n",
    "        #errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "\n",
    "        #Content loss\n",
    "        errAD = mix_par* F.mse_loss(fake, target)\n",
    "        total_error = errAD + errG\n",
    "        total_error.backward()\n",
    "\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "#         if i % 50 == 0:\n",
    "#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "#                   % (epoch, num_epochs, i, len(train_loader),\n",
    "#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = modelG(fixed_data.float()).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "#         print(iters)\n",
    "print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_loader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target) in enumerate((train_loader)):\n",
    "    data = data.to(device)\n",
    "    output = modelG(data.float()).detach().cpu()\n",
    "    #print(output.shape)\n",
    "    plt.figure(figsize=(15,25))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(np.transpose(data[0].detach().cpu(), (1, 2, 0)))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(np.transpose(output[0], (1, 2, 0)))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(np.transpose(target[0], (1, 2, 0)))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(train_loader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "print(real_batch[0][0].shape)\n",
    "plt.imshow(np.transpose(real_batch[0][0], (1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "287f18c9239a92122d056f26584831efad723dfd70eb05706cffaa935da93c89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
