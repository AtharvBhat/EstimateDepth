{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd76856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from unet_model import UNet\n",
    "from discriminator import Discriminator\n",
    "from torchinfo import summary\n",
    "from kornia.filters import spatial_gradient\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path=\"dataset/x_train.npy\", y_path=\"dataset/y_train.npy\", transform_flag=False):\n",
    "        self.X = np.load(X_path).transpose(0, 3, 1, 2)\n",
    "        self.y = np.load(y_path)\n",
    "        self.transform_flag = transform_flag\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def transform(self, image, mask):\n",
    "        # Random crop\n",
    "        image = torch.tensor(image)\n",
    "        mask = torch.tensor(mask)\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(480,480))\n",
    "        image = transforms.functional_tensor.crop(image, i, j, h, w)\n",
    "        mask = transforms.functional_tensor.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = transforms.functional_tensor.hflip(image)\n",
    "            mask = transforms.functional_tensor.hflip(mask)\n",
    "        \n",
    "        # Random brightness\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_brightness(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Contrast\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_contrast(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Gamma\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_gamma(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        # Random Hue\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_hue(image, np.random.rand() - 0.5)\n",
    "            \n",
    "        # Random Saturation\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_saturation(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform_flag:\n",
    "            return self.transform(self.X[idx], np.expand_dims(self.y[idx], 0))\n",
    "        else:\n",
    "            return self.X[idx], np.expand_dims(self.y[idx], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec203ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"dataset/x_train.npy\", \"dataset/y_train.npy\", transform_flag=True)\n",
    "val_dataset = MyDataset(\"dataset/x_val.npy\", \"dataset/y_val.npy\", transform_flag=False)\n",
    "test_dataset = MyDataset(\"dataset/x_test.npy\", \"dataset/y_test.npy\", transform_flag=False)\n",
    "\n",
    "#hyper params\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2dfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "generator = UNet(3, 1, bilinear=False)\n",
    "generator.load_state_dict(torch.load(\"models/Unet_l1/model_100.pth\"))\n",
    "generator = generator.to(device)\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=1e-4, weight_decay = 1e-5)\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator = discriminator.to(device)\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=1e-4, weight_decay= 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b2b588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleInvLoss(pred, groundtruth, lamda = 1, grad=True):\n",
    "    #as implemented in https://arxiv.org/pdf/1406.2283.pdf\n",
    "    log_pred = torch.log(pred)\n",
    "    log_gt = torch.log(groundtruth)\n",
    "    d = log_pred - log_gt\n",
    "    n = torch.numel(pred)\n",
    "    first_term = torch.sum(d**2)/n\n",
    "    second_term = torch.sum(d)**2 / n**2\n",
    "    if grad:\n",
    "        grad = spatial_gradient(d)\n",
    "        grad = torch.mean(grad**2)\n",
    "        return first_term - lamda * second_term + grad\n",
    "    else:\n",
    "        return first_term - lamda * second_term\n",
    "\n",
    "def train(epoch):\n",
    "    generator_content_loss = 0\n",
    "    generator_advarsarial_loss = 0\n",
    "    discriminator_total_loss = 0\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    print(f\"Training Epoch {epoch}\")\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        #get real samples\n",
    "        data, real_target = data.to(device), target.to(device)\n",
    "        \n",
    "        #get fake targets\n",
    "        fake_target = generator(data.float())\n",
    "        \n",
    "        #update discriminator for real and fake samples\n",
    "        discriminator_output_real = discriminator(real_target)\n",
    "        discriminator_output_fake = discriminator(fake_target.detach())\n",
    "        \n",
    "        #generate real and fake labels\n",
    "        fake_label = torch.zeros_like(discriminator_output_fake)\n",
    "        real_label = torch.ones_like(discriminator_output_real)\n",
    "        \n",
    "        discriminator_loss_real = F.binary_cross_entropy_with_logits(discriminator_output_real, real_label)\n",
    "        discriminator_loss_fake = F.binary_cross_entropy_with_logits(discriminator_output_fake, fake_label)\n",
    "        \n",
    "        discriminator_loss = (discriminator_loss_real + discriminator_loss_fake)/2\n",
    "        discriminator_total_loss += discriminator_loss \n",
    "        discriminator_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        #train generator\n",
    "        optimizerG.zero_grad()\n",
    "        content_loss = F.mse_loss(fake_target, real_target)\n",
    "        advarsarial_loss = F.binary_cross_entropy_with_logits(discriminator_output_fake.detach(), real_label)\n",
    "        generator_loss = content_loss + 0.5*advarsarial_loss\n",
    "        generator_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        generator_content_loss += content_loss\n",
    "        generator_advarsarial_loss += advarsarial_loss\n",
    "\n",
    "    discriminator_total_loss /= len(train_loader.dataset)\n",
    "    generator_content_loss /= len(train_loader.dataset)\n",
    "    generator_advarsarial_loss /= len(train_loader.dataset)\n",
    "    print(f\"Training : Epoch {epoch} : Content Loss : {generator_content_loss}, Advarsarial Loss : {generator_advarsarial_loss} discriminator loss : {discriminator_total_loss}\")\n",
    "    return (generator_content_loss, generator_advarsarial_loss, discriminator_total_loss)\n",
    "\n",
    "def validation():\n",
    "    generator_content_loss = 0\n",
    "    generator_advarsarial_loss = 0\n",
    "    discriminator_total_loss = 0\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    print(f\"Validating Epoch {epoch}\")\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(val_loader)):\n",
    "        with torch.no_grad():\n",
    "            #get real samples\n",
    "            data, real_target = data.to(device), target.to(device)\n",
    "        \n",
    "            #get fake targets\n",
    "            fake_target = generator(data.float())\n",
    "        \n",
    "            #update discriminator for real and fake samples\n",
    "            discriminator_output_real = discriminator(real_target)\n",
    "            discriminator_output_fake = discriminator(fake_target)\n",
    "            \n",
    "            #generate real and fake labels\n",
    "            fake_label = torch.zeros_like(discriminator_output_fake)\n",
    "            real_label = torch.ones_like(discriminator_output_real)\n",
    "            \n",
    "            discriminator_loss_real = F.binary_cross_entropy_with_logits(discriminator_output_real, real_label)\n",
    "            discriminator_loss_fake = F.binary_cross_entropy_with_logits(discriminator_output_fake, fake_label)\n",
    "        \n",
    "            discriminator_loss = (discriminator_loss_real + discriminator_loss_fake)/2\n",
    "            discriminator_total_loss += discriminator_loss\n",
    "        \n",
    "            #train generator\n",
    "            content_loss = F.mse_loss(fake_target, real_target)\n",
    "            advarsarial_loss = F.binary_cross_entropy_with_logits(discriminator_output_fake, real_label)\n",
    "            generator_loss = content_loss + 0.5*advarsarial_loss\n",
    "        \n",
    "            generator_content_loss += content_loss\n",
    "            generator_advarsarial_loss += advarsarial_loss\n",
    "\n",
    "    discriminator_total_loss /= len(train_loader.dataset)\n",
    "    generator_content_loss /= len(train_loader.dataset)\n",
    "    generator_advarsarial_loss /= len(train_loader.dataset)\n",
    "    print(f\"Validation : Epoch {epoch} : Content Loss : {generator_content_loss}, Advarsarial Loss : {generator_advarsarial_loss} discriminator loss : {discriminator_total_loss}\")\n",
    "    return (generator_content_loss, generator_advarsarial_loss, discriminator_total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089ba962e5604ec789c4e3f56d3d0723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Content Loss : 1.9430426359176636, Advarsarial Loss : 6.959269046783447 discriminator loss : 0.012601924128830433\n",
      "Running Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858d7efdfc424f5d9548aaf5f642c86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Content Loss : 0.5731709599494934, Advarsarial Loss : 0.3328573405742645 discriminator loss : 0.2953546643257141\n",
      "Running Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133e883ff6cb453c80998a62803ee61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "learning_rate = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(epoch)\n",
    "    train_loss.append(loss)\n",
    "    loss = validation()\n",
    "    validation_loss.append(loss)\n",
    "    model_file = 'models/gan/model_' + str(epoch) + '.pth'\n",
    "    torch.save(generator.state_dict(), model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
