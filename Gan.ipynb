{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd76856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from unet_model import UNet\n",
    "from discriminator import Discriminator\n",
    "from torchinfo import summary\n",
    "from kornia.filters import spatial_gradient\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path=\"dataset/x_train.npy\", y_path=\"dataset/y_train.npy\", transform_flag=False):\n",
    "        self.X = np.load(X_path).transpose(0, 3, 1, 2)\n",
    "        self.y = np.load(y_path)\n",
    "        self.transform_flag = transform_flag\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def transform(self, image, mask):\n",
    "        # Random crop\n",
    "        image = torch.tensor(image)\n",
    "        mask = torch.tensor(mask)\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(480,480))\n",
    "        image = transforms.functional_tensor.crop(image, i, j, h, w)\n",
    "        mask = transforms.functional_tensor.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = transforms.functional_tensor.hflip(image)\n",
    "            mask = transforms.functional_tensor.hflip(mask)\n",
    "        \n",
    "        # Random brightness\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_brightness(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Contrast\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_contrast(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Gamma\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_gamma(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        # Random Hue\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_hue(image, np.random.rand() - 0.5)\n",
    "            \n",
    "        # Random Saturation\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_saturation(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform_flag:\n",
    "            return self.transform(self.X[idx], np.expand_dims(self.y[idx], 0))\n",
    "        else:\n",
    "            return self.X[idx], np.expand_dims(self.y[idx], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec203ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"dataset/x_train.npy\", \"dataset/y_train.npy\", transform_flag=True)\n",
    "val_dataset = MyDataset(\"dataset/x_val.npy\", \"dataset/y_val.npy\", transform_flag=False)\n",
    "test_dataset = MyDataset(\"dataset/x_test.npy\", \"dataset/y_test.npy\", transform_flag=False)\n",
    "\n",
    "#hyper params\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2dfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "generator = UNet(3, 1, bilinear=False)\n",
    "generator.load_state_dict(torch.load(\"models/Unet_l1/model_100.pth\"))\n",
    "generator = generator.to(device)\n",
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=1e-4, weight_decay = 1e-5)\n",
    "\n",
    "discriminator = Discriminator()\n",
    "discriminator = discriminator.to(device)\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=1e-4, weight_decay= 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleInvLoss(pred, groundtruth, lamda = 1, grad=True):\n",
    "    #as implemented in https://arxiv.org/pdf/1406.2283.pdf\n",
    "    log_pred = torch.log(pred)\n",
    "    log_gt = torch.log(groundtruth)\n",
    "    d = log_pred - log_gt\n",
    "    n = torch.numel(pred)\n",
    "    first_term = torch.sum(d**2)/n\n",
    "    second_term = torch.sum(d)**2 / n**2\n",
    "    if grad:\n",
    "        grad = spatial_gradient(d)\n",
    "        grad = torch.mean(grad**2)\n",
    "        return first_term - lamda * second_term + grad\n",
    "    else:\n",
    "        return first_term - lamda * second_term\n",
    "\n",
    "def train(epoch):\n",
    "    generator_content_loss = 0\n",
    "    generator_advarsarial_loss = 0\n",
    "    discriminator_total_loss = 0\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    print(f\"Training Epoch {epoch}\")\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        #get real samples\n",
    "        data, real_target = data.to(device), target.to(device)\n",
    "        \n",
    "        #get fake targets\n",
    "        fake_target = generator(data.float())\n",
    "        \n",
    "        #update discriminator for real and fake samples\n",
    "        discriminator_output_real = discriminator(real_target)\n",
    "        discriminator_output_fake = discriminator(fake_target.detach())\n",
    "        \n",
    "        #generate real and fake labels\n",
    "        fake_label = torch.zeros_like(discriminator_output_fake)\n",
    "        real_label = torch.ones_like(discriminator_output_real)\n",
    "        \n",
    "        discriminator_loss_real = F.binary_cross_entropy_with_logits(discriminator_output_real, real_label)\n",
    "        discriminator_loss_fake = F.binary_cross_entropy_with_logits(discriminator_output_fake, fake_label)\n",
    "        \n",
    "        discriminator_loss = (discriminator_loss_real + discriminator_loss_fake)/2\n",
    "        discriminator_total_loss += discriminator_loss \n",
    "        discriminator_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        #train generator\n",
    "        optimizerG.zero_grad()\n",
    "        fake_target = generator(data.float())\n",
    "        discriminator_output_fake = discriminator(fake_target)\n",
    "        content_loss = F.mse_loss(fake_target, real_target)\n",
    "        advarsarial_loss = F.binary_cross_entropy_with_logits(discriminator_output_fake, real_label)\n",
    "        generator_loss = content_loss + 0.5*advarsarial_loss\n",
    "        generator_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        generator_content_loss += content_loss\n",
    "        generator_advarsarial_loss += advarsarial_loss\n",
    "\n",
    "    discriminator_total_loss /= len(train_loader.dataset)\n",
    "    generator_content_loss /= len(train_loader.dataset)\n",
    "    generator_advarsarial_loss /= len(train_loader.dataset)\n",
    "    print(f\"Training : Epoch {epoch} : Content Loss : {generator_content_loss}, Advarsarial Loss : {generator_advarsarial_loss} discriminator loss : {discriminator_total_loss}\")\n",
    "    return (generator_content_loss, generator_advarsarial_loss, discriminator_total_loss)\n",
    "\n",
    "def validation():\n",
    "    generator_content_loss = 0\n",
    "    generator_advarsarial_loss = 0\n",
    "    discriminator_total_loss = 0\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    print(f\"Validating Epoch {epoch}\")\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(val_loader)):\n",
    "        with torch.no_grad():\n",
    "            #get real samples\n",
    "            data, real_target = data.to(device), target.to(device)\n",
    "        \n",
    "            #get fake targets\n",
    "            fake_target = generator(data.float())\n",
    "        \n",
    "            #update discriminator for real and fake samples\n",
    "            discriminator_output_real = discriminator(real_target)\n",
    "            discriminator_output_fake = discriminator(fake_target)\n",
    "            \n",
    "            #generate real and fake labels\n",
    "            fake_label = torch.zeros_like(discriminator_output_fake)\n",
    "            real_label = torch.ones_like(discriminator_output_real)\n",
    "            \n",
    "            discriminator_loss_real = F.binary_cross_entropy_with_logits(discriminator_output_real, real_label)\n",
    "            discriminator_loss_fake = F.binary_cross_entropy_with_logits(discriminator_output_fake, fake_label)\n",
    "        \n",
    "            discriminator_loss = (discriminator_loss_real + discriminator_loss_fake)/2\n",
    "            discriminator_total_loss += discriminator_loss\n",
    "        \n",
    "            #train generator\n",
    "            content_loss = F.mse_loss(fake_target, real_target)\n",
    "            advarsarial_loss = F.binary_cross_entropy_with_logits(discriminator_output_fake, real_label)\n",
    "            generator_loss = content_loss + 0.5*advarsarial_loss\n",
    "        \n",
    "            generator_content_loss += content_loss\n",
    "            generator_advarsarial_loss += advarsarial_loss\n",
    "\n",
    "    discriminator_total_loss /= len(train_loader.dataset)\n",
    "    generator_content_loss /= len(train_loader.dataset)\n",
    "    generator_advarsarial_loss /= len(train_loader.dataset)\n",
    "    print(f\"Validation : Epoch {epoch} : Content Loss : {generator_content_loss}, Advarsarial Loss : {generator_advarsarial_loss} discriminator loss : {discriminator_total_loss}\")\n",
    "    return (generator_content_loss, generator_advarsarial_loss, discriminator_total_loss)\n",
    "\n",
    "def test():\n",
    "    images, predictions, ground_truths = [], [], []\n",
    "    generator.eval()\n",
    "    test_loss = 0\n",
    "    print(\"Visualizing test results\")\n",
    "    for data, target in tqdm(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = generator(data.float())\n",
    "        test_loss += scaleInvLoss(output, target).item() # sum up batch loss\n",
    "        images.append(data.detach().cpu())\n",
    "        predictions.append(output.detach().cpu())\n",
    "        ground_truths.append(target.detach().cpu())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'test set: Average loss: {test_loss}')\n",
    "    \n",
    "    return images, predictions, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "learning_rate = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train(epoch)\n",
    "    train_loss.append(loss)\n",
    "    loss = validation()\n",
    "    validation_loss.append(loss)\n",
    "    model_file = 'models/gan/model_' + str(epoch) + '.pth'\n",
    "    torch.save(generator.state_dict(), model_file)\n",
    "    images, predictions, ground_truths = test()\n",
    "    fig, axes = plt.subplots(5, 3, figsize=(15, 30))\n",
    "    for i,ax in enumerate(axes):\n",
    "        image = np.squeeze(images[i])\n",
    "        pred = torch.exp(np.squeeze(predictions[i]))\n",
    "        ground_truth = np.squeeze(ground_truths[i])\n",
    "    \n",
    "        ax[0].imshow(image.permute(1, 2, 0))\n",
    "        ax[1].imshow(pred)\n",
    "        ax[2].imshow(ground_truth)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde1908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
