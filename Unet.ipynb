{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from unet_model import UNet\n",
    "from torchinfo import summary\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_path=\"dataset/x_train.npy\", y_path=\"dataset/y_train.npy\", transform_flag=False):\n",
    "        self.X = np.load(X_path).transpose(0, 3, 1, 2)\n",
    "        self.y = np.load(y_path)\n",
    "        self.transform_flag = transform_flag\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def transform(self, image, mask):\n",
    "        # Random crop\n",
    "        image = torch.tensor(image)\n",
    "        mask = torch.tensor(mask)\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(256,256))\n",
    "        image = transforms.functional_tensor.crop(image, i, j, h, w)\n",
    "        mask = transforms.functional_tensor.crop(mask, i, j, h, w)\n",
    "\n",
    "        # Random horizontal flipping\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = transforms.functional_tensor.hflip(image)\n",
    "            mask = transforms.functional_tensor.hflip(mask)\n",
    "        \n",
    "        # Random brightness\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_brightness(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Contrast\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_contrast(image, np.random.rand() + 0.5)\n",
    "        \n",
    "        # Random Gamma\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_gamma(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        # Random Hue\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_hue(image, np.random.rand() - 0.5)\n",
    "            \n",
    "        # Random Saturation\n",
    "        if np.random.rand() > 0.1:\n",
    "            image = transforms.functional_tensor.adjust_saturation(image, np.random.rand() + 0.5)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform_flag:\n",
    "            return self.transform(self.X[idx], np.expand_dims(self.y[idx], 0))\n",
    "        else:\n",
    "            return self.X[idx], np.expand_dims(self.y[idx], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12425056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"dataset/x_train.npy\", \"dataset/y_train.npy\", transform_flag=True)\n",
    "val_dataset = MyDataset(\"dataset/x_val.npy\", \"dataset/y_val.npy\", transform_flag=False)\n",
    "test_dataset = MyDataset(\"dataset/x_test.npy\", \"dataset/y_test.npy\", transform_flag=False)\n",
    "\n",
    "#hyper params\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = UNet(3, 1, bilinear=False)\n",
    "\n",
    "model.load_state_dict(torch.load(\"models/Unet_l1/model_100.pth\"))\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logMSE(pred, groundtruth, lamda = 0.5):\n",
    "    #as implemented in https://arxiv.org/pdf/1406.2283.pdf\n",
    "    log_pred = torch.log(pred)\n",
    "    log_gt = torch.log(groundtruth)\n",
    "    d = log_pred - log_gt\n",
    "    n = torch.numel(pred)\n",
    "    first_term = torch.sum(d**2)/n\n",
    "    second_term = torch.sum(d)**2 / n**2\n",
    "    \n",
    "    return first_term + lamda * second_term\n",
    "\n",
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    print(f\"Running Epoch {epoch}\")\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.float())\n",
    "        loss = logMSE(output, target)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch} : Avg Loss : {train_loss}\")\n",
    "    return train_loss\n",
    "        \n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data.float())\n",
    "        validation_loss += logMSE(output, target).item() # sum up batch loss\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print(f'Validation set: Average loss: {validation_loss}')\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "learning_rate = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    loss = train(epoch)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "    loss = validation()\n",
    "    validation_loss.append(loss)\n",
    "    \n",
    "    \n",
    "    scheduler.step(loss)\n",
    "    learning_rate.append(optimizer.param_groups[0]['lr'])\n",
    "    model_file = 'models/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c021773",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(list(range(len(train_loss))), train_loss, label=\"Training loss\")\n",
    "plt.plot(list(range(len(validation_loss))), validation_loss, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"model with best validation loss is {np.argmin(validation_loss)+1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
